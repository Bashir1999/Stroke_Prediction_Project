# Stroke_Prediction_Project
According to the World Health Organization (WHO), stroke is the second leading cause of death and the third leading cause of disability, responsible for 11% of total deaths. Nearly 800,000 people in the United States suffer from a stroke each year, with about three in four being first-time strokes.

This dataset is used to predict whether a patient is likely to get stroke based on the input pa- rameters like gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, body mass index, and smoking status. Each row in the data provides relavant information about the patient. The data contains 5110 observations with 12 attributes before data cleaning process.

The first thing we do before moving on to visualizing data is to clean data or to check wether the data that we use is usable. In this process, we eliminate any data that is NULL, eliminate abnormal values, inconsistent values, and duplicate values. Since, this dataset is already cleaned so we don't have to look for inconsistent values but still we check all of them once again because it is important to have a clean data without any problem before moving on to EDA. The first step is to import the necessary libraries.

I imported pandas, numpy matplotlib.pyplot, and seaborn to have a variety in visualizing. Next, af- ter reading the dataset, we start the cleaning process. We have to check all the categorical attributes and see if there are any category that doesn't make sense or we don't it. For example, we deleted Gender 'Other' as there was only one value and this category doesn't make sense. After checking them all, we check wether our dataset has any null values. I dropped null values that were in the bmi column. Next, I added two extra columns to my dataset so that I can visualize them better, I used pd.cut() function to do this job for me instead of long method of doing it. At the end, I checked for the duplicated values, since there was none, I continued with visualizing the data.
